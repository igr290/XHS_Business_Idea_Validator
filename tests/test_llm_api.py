"""
LLM API è¯Šæ–­æµ‹è¯•

ç”¨äºæ£€æŸ¥ OpenAI API é…ç½®æ˜¯å¦æ­£ç¡®
"""
import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
env_path = Path(__file__).parent.parent / ".env"
load_dotenv(env_path)


async def test_env_vars():
    """æµ‹è¯•ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®åŠ è½½"""
    print("=" * 60)
    print("æ­¥éª¤ 1: æ£€æŸ¥ç¯å¢ƒå˜é‡")
    print("=" * 60)

    api_key = os.getenv("OPENAI_API_KEY", "")
    base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")

    print(f"OPENAI_API_KEY: {'***' + api_key[-4:] if api_key and len(api_key) > 4 else 'æœªè®¾ç½®'}")
    print(f"OPENAI_BASE_URL: {base_url}")

    if not api_key or api_key == "your_openai_api_key_here":
        print("\nâŒ é”™è¯¯: OPENAI_API_KEY æœªé…ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼")
        print("   è¯·åœ¨ agent_system/.env æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„ OPENAI_API_KEY")
        return False

    if not api_key.startswith("sk-"):
        print("\nâš ï¸  è­¦å‘Š: OPENAI_API_KEY æ ¼å¼å¯èƒ½ä¸æ­£ç¡®")
        print("   OpenAI API Key é€šå¸¸ä»¥ 'sk-' å¼€å¤´")

    print("\nâœ“ ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡\n")
    return True


async def test_api_connection():
    """æµ‹è¯• API è¿æ¥"""
    print("=" * 60)
    print("æ­¥éª¤ 2: æµ‹è¯• API è¿æ¥")
    print("=" * 60)

    from mcp_servers.llm_server import create_llm_mcp_server

    api_key = os.getenv("OPENAI_API_KEY", "")
    base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
    model_name = os.getenv("OPENAI_MODEL", "gpt-4o")

    print(f"é…ç½®: model={model_name}, base_url={base_url}")

    try:
        # åˆ›å»ºæœåŠ¡å™¨
        server = await create_llm_mcp_server(
            api_key=api_key,
            base_url=base_url,
            model_name=model_name
        )

        # æµ‹è¯•è¿æ¥
        print("\næ­£åœ¨å‘é€æµ‹è¯•è¯·æ±‚...")
        result = await server.test_connection()

        # å…³é—­æœåŠ¡å™¨
        await server.stop()

        if result.get("success"):
            print(f"\nâœ… {result.get('message')}")
            return True
        else:
            print(f"\nâŒ è¿æ¥å¤±è´¥: {result.get('message')}")
            if result.get("error_type"):
                print(f"   é”™è¯¯ç±»å‹: {result.get('error_type')}")
            if result.get("error"):
                print(f"   é”™è¯¯è¯¦æƒ…: {result.get('error')}")
            return False

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_simple_generation():
    """æµ‹è¯•ç®€å•çš„æ–‡æœ¬ç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 3: æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ")
    print("=" * 60)

    from mcp_servers.llm_server import create_llm_mcp_server

    api_key = os.getenv("OPENAI_API_KEY", "")
    base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")

    try:
        server = await create_llm_mcp_server(
            api_key=api_key,
            base_url=base_url
        )

        print("\næ­£åœ¨ç”Ÿæˆæµ‹è¯•æ–‡æœ¬...")
        result = await server.generate_text(
            prompt="ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±",
            max_tokens=50
        )

        await server.stop()

        if result.get("success"):
            print(f"\nâœ… æ–‡æœ¬ç”ŸæˆæˆåŠŸ:")
            print(f"   {result.get('text')}")
            print(f"   è€—æ—¶: {result.get('execution_time', 0):.2f}s")
            return True
        else:
            print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {result.get('error')}")
            return False

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 60)
    print("LLM API è¯Šæ–­å·¥å…·")
    print("=" * 60)
    print(f"å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f".env è·¯å¾„: {env_path}")
    print(f".env å­˜åœ¨: {env_path.exists()}\n")

    # æ­¥éª¤ 1: æ£€æŸ¥ç¯å¢ƒå˜é‡
    env_ok = await test_env_vars()
    if not env_ok:
        return False

    # æ­¥éª¤ 2: æµ‹è¯• API è¿æ¥
    conn_ok = await test_api_connection()
    if not conn_ok:
        return False

    # æ­¥éª¤ 3: æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ
    gen_ok = await test_simple_generation()

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("è¯Šæ–­ç»“æœ")
    print("=" * 60)
    print(f"ç¯å¢ƒå˜é‡: {'âœ… é€šè¿‡' if env_ok else 'âŒ å¤±è´¥'}")
    print(f"API è¿æ¥: {'âœ… é€šè¿‡' if conn_ok else 'âŒ å¤±è´¥'}")
    print(f"æ–‡æœ¬ç”Ÿæˆ: {'âœ… é€šè¿‡' if gen_ok else 'âŒ å¤±è´¥'}")

    if env_ok and conn_ok and gen_ok:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼API é…ç½®æ­£å¸¸ã€‚")
        return True
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ ¹æ®ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯ä¿®å¤é…ç½®ã€‚")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
